{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette(\"GnBu_d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('car_price_data2.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check if there are any outliers\n",
    "# Here we conclude that we don't have any outliers as the values are gradually increasing!\n",
    "df.describe(percentiles=[0.25,0.5,0.75,0.9,0.95,0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information of the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking missing value\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new feature called total no. of years old my car,bcz It's important to know how many years old the car is.\n",
    "df['Car_age'] = 2020-df['Year']\n",
    "\n",
    "#It's time to drop the Year column after the needed info is derived.\n",
    "df.drop(labels='Year',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[17,5])\n",
    "plt.subplot(1,3,1)\n",
    "sns.barplot(df['Owner'],df['Selling_Price'])\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "sns.barplot(df['Car_age'],df['Selling_Price'])\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "sns.regplot(df['Selling_Price'],df['Kms_Driven'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[17,5])\n",
    "plt.subplot(1,3,1)\n",
    "sns.regplot(df['Selling_Price'],df['Present_Price'])\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "sns.distplot(np.log(df['Selling_Price']))\n",
    "plt.title('Distribution of Selling Price')\n",
    "\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "sns.distplot(np.log(df['Kms_Driven']))\n",
    "plt.title('Distribution of KMS Drived')\n",
    "\n",
    "\n",
    "plt.title('Kilometers Drived')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's our categorical column\n",
    "print(df['Fuel_Type'].unique())\n",
    "print(df['Seller_Type'].unique())\n",
    "print(df['Transmission'].unique())\n",
    "print(df['Car_Name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Car Name column There are three hundred and twelve unique name. \n",
    "# That's something really hard to implement and a regression that would mean more than 300 dummies, so we simply drop this column\n",
    "df = df.drop(labels='Car_Name', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing With Categorical Variables, creagting dummie\n",
    "clean_data = pd.get_dummies(df,drop_first=True)\n",
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "variables = clean_data[['Present_Price','Kms_Driven','Owner','Car_age','Fuel_Type_Diesel',\n",
    "                        'Fuel_Type_Petrol','Seller_Type_Individual','Transmission_Manual']]\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF\"] = [variance_inflation_factor(variables.values, i) for i in range(variables.shape[1])]\n",
    "vif[\"Features\"] = variables.columns\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Car_age nd fuel_type_petrol feature has high VIF\n",
    "data_no_multicolinearity = clean_data.drop(['Kms_Driven','Fuel_Type_Petrol'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cheking again after removing some correlated feature\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "variables = clean_data[['Present_Price','Owner','Car_age','Fuel_Type_Diesel',\n",
    "                        'Seller_Type_Individual','Transmission_Manual']]\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF\"] = [variance_inflation_factor(variables.values, i) for i in range(variables.shape[1])]\n",
    "vif[\"Features\"] = variables.columns\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation heat map\n",
    "plt.figure(figsize=[15,7])\n",
    "sns.heatmap(data_no_multicolinearity.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#F-regression create simple linear regression of each feature\n",
    "#This method would calculate the F statistic for each of those regressions and return the respective p values\n",
    "from sklearn.feature_selection import f_regression,SelectKBest\n",
    "\n",
    "X = data_no_multicolinearity.drop('Selling_Price',axis=1)\n",
    "y = data_no_multicolinearity['Selling_Price']\n",
    "\n",
    "f_regression(X,y)\n",
    "\n",
    "p_values = f_regression(X,y)[1]\n",
    "\n",
    "p_values.round(3) # This output in scincetific notation array lets convert them using 'round' method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating summary table\n",
    "model_summry = pd.DataFrame(data=['Present_Price', 'Owner', 'Car_age', 'Fuel_Type_Diesel',\n",
    "                              'Seller_Type_Individual', 'Transmission_Manual'], columns=['Features'])\n",
    "model_summry['p-values'] = p_values.round(3)\n",
    "model_summry.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important feature using ExtraTreesRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "model = ExtraTreesRegressor()\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot graph of feature importances for better visualization\n",
    "plt.figure(figsize=[12,6])\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(6).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feat_importances.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_multicolinearity.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting useful features.\n",
    "final_df = data_no_multicolinearity[['Selling_Price', 'Present_Price', 'Car_age',\n",
    "       'Fuel_Type_Diesel', 'Seller_Type_Individual', 'Transmission_Manual']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df.drop('Selling_Price', axis=1)\n",
    "y = final_df['Selling_Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scallng on training data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X[['Present_Price','Car_age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_scaled = scaler.transform(X[['Present_Price','Car_age']])\n",
    "scaled_data = pd.DataFrame(input_scaled, columns=['Present_Price','Car_age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled =scaled_data.join(X.drop(['Present_Price','Car_age'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(X_scaled,y,test_size=0.2, random_state=365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Building\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Training Model\n",
    "lr.fit(x_train,y_train)\n",
    "\n",
    "# Model Summary\n",
    "y_pred_lr = lr.predict(x_test)\n",
    "\n",
    "r_squared = r2_score(y_test,y_pred_lr)\n",
    "rmse = np.sqrt(mean_squared_error(y_test,y_pred_lr))\n",
    "print(\"R_squared :\",r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Training Model\n",
    "rf.fit(x_train,y_train)\n",
    "\n",
    "# Model Summary\n",
    "y_pred_rf = rf.predict(x_test)\n",
    "\n",
    "r_squared = r2_score(y_test,y_pred_rf)\n",
    "rmse = np.sqrt(mean_squared_error(y_test,y_pred_rf))\n",
    "print(\"R_squared :\",r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gbt = GradientBoostingRegressor()\n",
    "\n",
    "# Training Model\n",
    "gbt.fit(x_train,y_train)\n",
    "\n",
    "# Model Summary\n",
    "y_pred_gbt = gbt.predict(x_test)\n",
    "\n",
    "r_squared = r2_score(y_test,y_pred_gbt)\n",
    "rmse = np.sqrt(mean_squared_error(y_test,y_pred_gbt))\n",
    "print(\"R_squared :\",r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomized Search CV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n",
    "# max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10, 15, 100]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 5, 10]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10, cv = 5, verbose=2, random_state=42, n_jobs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=rf_random.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squared = r2_score(y_test,predictions)\n",
    "rmse = np.sqrt(mean_squared_error(y_test,predictions))\n",
    "print(\"R_squared :\",r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# save the model to disk\n",
    "import pickle\n",
    "pickle.dump(rf_random, open('rf_model', 'wb'))\n",
    "\n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open('rf_model','rb'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(PresentPrice, CarAge, FuelType,SellerType, Transmissionmanual):\n",
    "    # feature scaling on present price and car age\n",
    "    scaled_value = scaler.transform([[float(PresentPrice), int(CarAge)]])\n",
    "    \n",
    "    price = scaled_value[0,0]\n",
    "    age = scaled_value[0,1]\n",
    "    \n",
    "    fuel = int(FuelType)\n",
    "    Seller = int(SellerType)\n",
    "    trans = int(Transmissionmanual)\n",
    "    \n",
    "    return rf_random.predict([[price, age, fuel, Seller, trans]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction(25, 14, 0, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction(23.73, 14, 0, 1,0)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
